# FIDE Scraper

This directory contains scripts to scrape data from the FIDE website.

## Overview

The scraper consists of four main scripts that work together:

- **`get_federations.py`**: Scrapes the FIDE website to retrieve a list of all chess federations and saves them to a CSV file. This script fetches the list of federations from the FIDE ratings website (`https://ratings.fide.com/rated_tournaments.phtml`) and saves them with two columns: the 3-letter federation code and the full federation name.

- **`get_tournaments.py`**: Scrapes tournament lists for all federations for a given month and year. This script uses direct HTTP requests to JSON endpoints to efficiently fetch tournament data for each federation. It reads the federations CSV file generated by `get_federations.py` and outputs tournament IDs and metadata.

- **`get_tournament_details.py`**: Scrapes detailed tournament information for a list of tournament IDs. This script fetches comprehensive tournament details from individual tournament pages on the FIDE website, including tournament metadata, dates, arbiters, organizers, and other administrative information. It reads tournament IDs from files generated by `get_tournaments.py` and outputs Parquet and JSON sample files.

- **`get_tournament_reports.py`**: Scrapes tournament reports (original reports) for a list of tournament codes. This script fetches the results tables from FIDE report pages, extracts player data and round-by-round game results, and outputs a games Parquet file (one row per game) plus optional JSON/CSV samples. Throughput is naturally limited by fetch and parse time (~1 tournament/sec); no rate limiting is applied.

## Basic Usage

### Getting Federations

First, scrape the list of federations:

```bash
python src/scraper/get_federations.py
```

This will:
- Scrape the FIDE website
- Save the results to `data/federations.csv` (relative to the repo root)
- Print verbose output (all federations, count, and execution time)

### Getting Tournaments

Then, scrape tournaments for a specific month:

```bash
python src/scraper/get_tournaments.py --year 2025 --month 1
```

This will:
- Read federations from `data/federations.csv`
- Scrape tournaments for all federations for January 2025
- Save tournament IDs to `data/tournament_ids/2025_01`
- Save full tournament data as JSON to `data/tournament_ids_json/2025_01.json`

### Getting Tournament Details

Then, scrape detailed information for tournaments:

```bash
python src/scraper/get_tournament_details.py --year 2025 --month 1
```

This will:
- Read tournament IDs from `data/tournament_ids/2025_01`
- Scrape detailed tournament information from FIDE website
- Save all results to `data/tournament_details/2025_01.parquet` (efficient Parquet format)
- Save a random sample of 100 successful records to `data/tournament_details/2025_01_sample.json` (for quick inspection)
- Use rate limiting (default 0.5 req/s) to avoid overwhelming the server
- Automatically retry failed requests

### Getting Tournament Reports

Finally, after tournament details are scraped, scrape reports to extract game results:

```bash
python src/scraper/get_tournament_reports.py --year 2025 --month 1
```

This will:
- Read tournament codes from `data/tournament_details/2025_01.parquet` (successful records only)
- Scrape tournament report pages from FIDE website
- Save games to `data/tournament_reports/2025_01.parquet` (one row per game)
- Save JSON and CSV samples for inspection (unless `--no-samples` is used)
- Use date bounds from details for round date inference when available
- Run at natural throughput (~1 tournament/sec); no rate limiting
- Automatically retry failed requests

Alternatively, use `--input` with a tournament codes file and `--details-path` to load dates from an existing details Parquet.

## Command Line Arguments

### `get_federations.py`

| Argument | Short | Default | Description |
|----------|-------|---------|-------------|
| `--directory` | `-d` | `data` | Directory to output the result (relative to repo root) |
| `--filename` | `-f` | `federations.csv` | Output filename |
| `--quiet` | `-q` | `False` | Disable verbose output |
| `--override` | `-o` | `False` | Force re-scraping even if output file exists |

**Examples:**

```bash
# Custom output directory and filename
python src/scraper/get_federations.py --directory custom_data --filename my_federations.csv

# Quiet mode (minimal output)
python src/scraper/get_federations.py --quiet

# Force re-scrape even if file exists
python src/scraper/get_federations.py --override
```

### `get_tournaments.py`

| Argument | Short | Default | Description |
|----------|-------|---------|-------------|
| `--year` | | *required* | Year to scrape (e.g., 2025) |
| `--month` | | *required* | Month to scrape (1-12) |
| `--federations` | `-f` | `data/federations.csv` | Path to federations CSV file (relative to repo root) |
| `--output` | `-o` | `data/tournament_ids/YYYY_MM` | Output file path (relative to repo root) |
| `--format` | | `ids` | Output format: `ids` for just IDs, `json` for full tournament data |
| `--concurrency` | `-c` | `10` | Maximum number of concurrent requests |
| `--max-retries` | `-r` | `3` | Maximum number of retries per federation |
| `--retry-delay` | | `1.0` | Base delay in seconds between retries |
| `--quiet` | `-q` | `False` | Disable verbose output |

**Examples:**

```bash
# Scrape tournaments for January 2025
python src/scraper/get_tournaments.py --year 2025 --month 1

# Higher concurrency for faster scraping
python src/scraper/get_tournaments.py --year 2025 --month 1 --concurrency 20

# Custom federations file and output path
python src/scraper/get_tournaments.py --year 2025 --month 1 --federations custom_data/federations.csv --output custom_data/tournaments.txt

# Quiet mode
python src/scraper/get_tournaments.py --year 2025 --month 1 --quiet
```

### `get_tournament_details.py`

| Argument | Short | Default | Description |
|----------|-------|---------|-------------|
| `--input` | | | Path to tournament IDs file (alternative to --year/--month) |
| `--year` | | | Year to process (required if --input not specified) |
| `--month` | | | Month to process 1-12 (required if --input not specified) |
| `--data-dir` | | `data` | Base data directory (relative to repo root) |
| `--output` | | | Output base path (auto-generated from year/month if not specified) |
| `--rate-limit` | | `0.5` | Requests per second (FIDE throttles above ~0.6; 0.5 is safe) |
| `--max-retries` | | `3` | Maximum number of retry passes |
| `--checkpoint` | | `100` | Save checkpoint every N successful tournaments |
| `--show-time` | | `False` | Show timing info for each tournament |
| `--verbose` | | `False` | Use verbose stdout output instead of progress bar |
| `--limit` | | `0` | Process only first N tournaments (for testing) |
| `--verbose-errors` | | `False` | Log failed HTTP attempts and print retry analysis at end |

**Examples:**

```bash
# Scrape tournament details for January 2025
python src/scraper/get_tournament_details.py --year 2025 --month 1

# Use custom input file and output path
python src/scraper/get_tournament_details.py --input data/tournament_ids/custom.txt --output data/details/custom.parquet
# This creates: data/details/custom.parquet and data/details/custom_sample.json

# Verbose mode with detailed error information
python src/scraper/get_tournament_details.py --year 2025 --month 1 --verbose

# Error analysis (for debugging rate limits)
python src/scraper/get_tournament_details.py --year 2025 --month 1 --verbose-errors --limit 20

# More frequent checkpoints
python src/scraper/get_tournament_details.py --year 2025 --month 1 --checkpoint 50
```

### `get_tournament_reports.py`

| Argument | Short | Default | Description |
|----------|-------|---------|-------------|
| `--input` | | | Path to tournament codes file (alternative to --year/--month) |
| `--year` | | | Year to process (required if --input not specified) |
| `--month` | | | Month to process 1-12 (required if --input not specified) |
| `--data-dir` | | `data` | Base data directory (relative to repo root) |
| `--output` | | | Output base path (auto-generated from year/month if not specified) |
| `--details-path` | | | Path to tournament details Parquet (for date inference) |
| `--max-retries` | | `3` | Maximum number of retry passes |
| `--checkpoint` | | `50` | Save checkpoint every N successful tournaments |
| `--show-time` | | `False` | Show timing info for each tournament |
| `--verbose` | | `False` | Use verbose stdout output instead of progress bar |
| `--no-samples` | | `False` | Skip JSON and CSV sample outputs (Parquet only) |
| `--limit` | | `0` | Process only first N tournaments (for testing) |
| `--verbose-errors` | | `False` | Log failed HTTP attempts and print retry analysis at end |

**Examples:**

```bash
# Scrape tournament reports for January 2025 (reads tournament IDs from get_tournaments output)
python src/scraper/get_tournament_reports.py --year 2025 --month 1

# Use custom input with details for date inference
python src/scraper/get_tournament_reports.py --input codes.txt --output data/reports/custom.parquet --details-path data/tournament_details/2025_01.parquet

# Parquet only, no samples
python src/scraper/get_tournament_reports.py --year 2025 --month 1 --no-samples

# Quick test with first 20 tournaments
python src/scraper/get_tournament_reports.py --year 2025 --month 1 --limit 20
```

## Behavior

### `get_federations.py`

**File Existence Check:**
- By default, if the output file already exists, the script will print a message and exit without scraping
- Use the `--override` flag to force re-scraping and overwrite the existing file

**Retry Logic:**
- Automatic retry logic with exponential backoff
- Up to 3 retry attempts on failure
- Exponential backoff between retries (1s, 2s, 3s)
- Handles network errors and parsing errors

**Verbose Output:**
When verbose mode is enabled (default), the script prints:
1. All federations in the format: `CODE: Full Name`
2. The total count of federations
3. The execution time in seconds

**Output Format:**
The script generates a CSV file with the following structure:

```csv
code,name
AFG,Afghanistan
ALB,Albania
...
ZIM,Zimbabwe
```

- **code**: 3-letter federation abbreviation
- **name**: Full federation name

### `get_tournaments.py`

**Output Files:**
- Always saves two files:
  - IDs file: `data/tournament_ids/YYYY_MM` (one tournament ID per line)
  - JSON file: `data/tournament_ids_json/YYYY_MM.json` (full tournament data with metadata)

**Tournament Data:**
Each tournament includes:
- `tournament_id`: Unique tournament identifier
- `name`: Tournament name
- `location`: Tournament location
- `time_control`: Time control type (`s` = standard, `r` = rapid, `b` = blitz)
- `start_date`: Tournament start date
- `end_date`: Tournament end date
- `federation`: Federation code

**Graceful Shutdown:**
- Supports graceful shutdown on SIGINT (Ctrl+C) or SIGTERM
- Saves partial results if interrupted
- Prints summary of progress

**Deduplication:**
- Automatically removes duplicate tournaments by tournament ID
- Sorts tournaments by ID in output files

**Progress Tracking:**
- Shows progress updates every 10 federations
- Displays elapsed time and estimated remaining time
- Provides summary statistics at completion

### `get_tournament_details.py`

**Input/Output:**
- Reads tournament IDs from a file (one ID per line)
- Can use `--input` to specify a file, or `--year`/`--month` to auto-detect from `data/tournament_ids/YYYY_MM`
- Outputs data in two formats:
  - **Parquet file** (`YYYY_MM.parquet`): All tournament data in efficient columnar Parquet format for fast analysis and processing
  - **JSON sample** (`YYYY_MM_sample.json`): Random sample of 100 successful tournament records in JSON format for quick inspection and validation
- Auto-generates output paths from year/month if not specified: `data/tournament_details/YYYY_MM.parquet` and `data/tournament_details/YYYY_MM_sample.json`
- Parquet format provides significant storage efficiency and faster query performance compared to JSON
- List fields (arbiters, organizers) are stored as semicolon-separated strings in Parquet for compatibility

**Rate Limiting:**
- Uses fixed-interval rate limiting (no bursting)
- Default 0.5 req/s: FIDE's details endpoint throttles above ~0.6 req/s (connection resets)
- Higher rates cause `RemoteDisconnected` errors and multiple HTTP retries per tournament

**Retry Logic:**
- Automatic retry passes for network errors (timeouts, connection resets, etc.)
- Exponential backoff between retry passes (3s, 6s, 12s)
- Distinguishes between retryable network errors and permanent failures
- Only retries network-related errors, not parsing or "no data" errors

**Progress Tracking:**
- Two output modes:
  - **Progress bar mode (default)**: Compact progress bar with success/error counts, retry info, rate, and time estimates
  - **Verbose mode (`--verbose`)**: Detailed stdout output for each tournament with full error messages, retry status, and comprehensive statistics
- Real-time statistics: success count, error count, retry count, current rate, elapsed time, estimated remaining time
- Periodic summary updates (every 50 tournaments in progress bar mode)

**Checkpointing:**
- Saves checkpoint files periodically (default: every 100 successful tournaments)
- Checkpoint files saved as Parquet format: `{output_file}.parquet.checkpoint`
- Allows resuming from last checkpoint if script is interrupted
- Final results always saved to main Parquet and JSON sample files
- Checkpoints use the same efficient Parquet format as the final output

**Output Format:**
- **Parquet files** can be read with pandas, PyArrow, or any Parquet-compatible tool:
  ```python
  import pandas as pd
  df = pd.read_parquet('data/tournament_details/2025_01.parquet')
  ```
- Parquet provides significant advantages over JSON:
  - **Storage efficiency**: Typically 5-10x smaller file sizes
  - **Fast queries**: Columnar format enables efficient filtering and aggregation
  - **Type preservation**: Data types are preserved (dates, numbers, booleans)
  - **Schema evolution**: Easy to add new columns without breaking existing data
- **JSON sample files** contain a random sample of 100 successful tournament records for:
  - Quick inspection and validation
  - Understanding the data structure
  - Testing and development
  - Human-readable format for debugging

**Tournament Details:**
Each tournament detail includes:
- `event_code`: Tournament event code
- `tournament_name`: Full tournament name
- `city`, `country`: Location information
- `number_of_players`: Number of participants
- `system`: Tournament system (Swiss, Round Robin, etc.)
- `category`: Tournament category
- `start_date`, `end_date`: Tournament dates
- `date_received`, `date_registered`: Administrative dates
- `type`: Tournament type
- `time_control`: Time control information
- `zone`: FIDE zone
- `chief_arbiter`, `deputy_chief_arbiter`, `arbiter`, `assistant_arbiter`: Lists of arbiters (stored as semicolon-separated strings in Parquet)
- `chief_organizer`, `organizer`: Lists of organizers (stored as semicolon-separated strings in Parquet)
- `nat_championship`: National championship indicator
- `pgn_file`: PGN file link
- `orig_report`, `view_report_href`, `view_report_text`: Report links

**Diagnostics (--verbose-errors):**
- `--verbose-errors`: Logs each failed HTTP attempt and prints summary: attempt distribution (how many need 1/2/3 attempts), list of tournaments needing retries, error breakdown by type

**Note on List Fields:**
In the Parquet format, list fields (arbiters, organizers) are stored as semicolon-separated strings for compatibility. To split them back into lists:
```python
df['chief_arbiter'] = df['chief_arbiter'].str.split(';')
```
In the JSON sample files, these fields remain as proper JSON arrays.

**Error Handling:**
- Detects various connection error types (EOF, connection reset, connection aborted, RemoteDisconnected, etc.)
- Marks network errors for retry
- Provides detailed error messages in verbose mode

### `get_tournament_reports.py`

**Input/Output:**
- Reads tournament codes from a file, or from `data/tournament_ids/YYYY_MM` (output of `get_tournaments.py`) when using `--year`/`--month`
- If `get_tournament_details` output exists (`data/tournament_details/YYYY_MM.parquet`), it is used only for start/end dates to improve date format inference
- With `--input`, use `--details-path` to optionally supply a details Parquet for date inference
- Outputs:
  - **Parquet file** (main): One row per game (tournament_code, round, date, white_id, black_id, white_score, forfeit). Games are deduplicated (each game appears once, from white player's perspective)
  - **JSON sample**: Random sample of player-round rows (verbose format with all fields)
  - **CSV sample**: Same as JSON but CSV format
- Auto-generates paths from year/month: `data/tournament_reports/YYYY_MM.parquet`, `_sample.json`, `_sample.csv`
- Use `--no-samples` to skip JSON/CSV and only write Parquet

**Throughput:**
- No rate limiting; throughput is naturally limited by fetch (~0.8s) + parse (~0.3s) per tournament (~1 tournament/sec)
- FIDE's reports endpoint tolerates higher rates than details; no connection resets observed at 2â€“10 req/s in testing

**Retry Logic:**
- Same as details: automatic retry passes for network errors (timeouts, connection resets, etc.)
- Exponential backoff between retry passes (3s, 6s, 12s)
- Only retries network-related errors, not "no data found" or parsing errors

**Progress Tracking:**
- Same modes as details: progress bar (default) or verbose stdout
- Real-time statistics: success count, error count, retry count, actual rate, elapsed time, estimated remaining time

**Checkpointing:**
- Saves checkpoint every N successful tournaments (default: 50)
- Checkpoint format: `{output_file}.parquet.checkpoint`

**Date Inference:**
- Round dates in reports use formats like `yy/mm/dd` or `dd/mm/yy`; the script infers format from date ranges
- When tournament details Parquet is available (auto-detected for `--year`/`--month`, or via `--details-path` with `--input`), uses start/end dates to constrain inference for better accuracy
- Output Parquet uses ISO dates (YYYY-MM-DD) for games

**Game Data:**
Each game row includes:
- `tournament_code`, `round`, `date` (ISO), `white_id`, `black_id`, `white_score` (1.0=white win, 0.5=draw, 0.0=black win), `forfeit` (boolean)

## Error Handling

All scripts handle various error conditions:
- Network timeouts and connection errors (with retries)
- Missing HTML elements or malformed JSON (raises appropriate errors)
- File I/O errors

On error, the scripts will:
- Print an error message
- Return exit code 1 (or 130 for SIGINT in `get_tournaments.py`)

**`get_tournament_details.py` and `get_tournament_reports.py` error handling:**
- Network errors (timeouts, connection resets, etc.) are automatically retried
- Permanent errors (parsing failures, no data found) are logged but not retried
- Checkpoint files preserve progress even if script is interrupted
- Final summary shows success rate, error count, and retry statistics
